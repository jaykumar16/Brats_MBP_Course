{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "import joblib\n",
    "from torch.optim import Adam, SGD\n",
    "from dataprepaug import *\n",
    "from utils import *\n",
    "from models import *\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "#from models.unet_model import UNet\n",
    "from models.UnetPlusPlus import NestedUNet\n",
    "\n",
    "#from .pspnet import *\n",
    "#from .deeplab import *\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from models.unet import *\n",
    "import glob\n",
    "import os\n",
    "import numbers\n",
    "import math\n",
    "import PIL\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import collections\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from optuna import Trial\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(traindataload,net,optimizer, grad_sc,epoch,device):\n",
    "        \n",
    "        loss = 0\n",
    "        epoch_loss = 0\n",
    "        size=0\n",
    "        acc=0\n",
    "        nbatch = len(traindataload)\n",
    "        for idx, (inputs, targets) in enumerate(traindataload):\n",
    "                torch.cuda.empty_cache()\n",
    "                inputs, targets = inputs.to(device).to(memory_format=torch.contiguous_format), targets.to(device).to(memory_format=torch.contiguous_format)\n",
    "                outputs = net(inputs)\n",
    "                size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "                batch_loss = dice_loss(outputs.softmax(1),targets, multiclass=True)\n",
    "                optimizer.zero_grad()\n",
    "                grad_sc.scale(batch_loss).backward()\n",
    "                grad_sc.step(optimizer)\n",
    "                grad_sc.update()\n",
    "                loss = batch_loss.item()\n",
    "                epoch_loss += loss\n",
    "                acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                progress_bar(idx, len(traindataload), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %(loss, 1-loss))#(loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "                log_msg = '\\n'.join(['Training (%d/%d): Epoch: %d, Loss: %.5f,  Dice-Coef:  %.5f' %(idx,nbatch, epoch,loss, 1-loss)])\n",
    "                logging.info(log_msg)\n",
    "        epoch_loss /= nbatch\n",
    "        acc /= size\n",
    "        \n",
    "        print(f\"Training epoch error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {epoch_loss:>8f}, Dice: {(1-epoch_loss):>8f} \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def validation(validationload,net,epoch,device):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        size=0\n",
    "        nbatch = len(validationload)\n",
    "        with torch.no_grad():\n",
    "                for idx, (inputs, targets) in enumerate(validationload):\n",
    "                        torch.cuda.empty_cache()\n",
    "                        inputs, targets = inputs.to(device).to(memory_format=torch.contiguous_format), targets.to(device).to(memory_format=torch.contiguous_format)\n",
    "                        outputs = net(inputs)\n",
    "                        loss += dice_loss(outputs.softmax(1),targets, multiclass=True).item()\n",
    "                        acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                        size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "            \n",
    "                        \n",
    "                        progress_bar(idx, len(validationload), 'Loss: %.5f, Dice-Coef: %.5f' %(loss/(idx+1), 1-(loss/(idx+1))))\n",
    "                        log_msg = '\\n'.join(['Validation (%d/%d): Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                %(idx, nbatch, epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "                        logging.info(log_msg)\n",
    "        \n",
    "        loss /= nbatch\n",
    "        acc /= size\n",
    "        torch.cuda.empty_cache()                \n",
    "        print(f\"Validation error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {loss:>8f}, Dice: {(1-loss):>8f} \\n\")\n",
    "        return loss, acc\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "        \n",
    "        \n",
    "    \n",
    "# def optumaParams(trial):\n",
    "#         device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         config = {\n",
    "#         \"layer_multipler\": trial.suggest_int(\"layer_multipler\", 16,42),\n",
    "#         \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-1),\n",
    "#         \"drop_rate\": trial.suggest_loguniform(\"drop_rate\", 1e-2, 2.5e-1),\n",
    "#         \"n_layers\": trial.suggest_int(\"n_layers\",3,4),\n",
    "#         \"batch_size\": trial.suggest_int(\"batch_size\",4,15),\n",
    "#         \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"SGD\", \"Adam\", \"RMSprop\"])\n",
    "#     }\n",
    "\n",
    "        \n",
    "#         net = NestedUNet(num_classes= 4, input_channels=4,layer_multipler= config[\"layer_multipler\"], n_layers=config[\"n_layers\"],\n",
    "#                    drop_rate=config[\"drop_rate\"])\n",
    "#         #print(f'Layer_Muti: {config[\"layer_multipler\"]}')\n",
    "#         net = net.to(device)    \n",
    "#         optimizer = getattr(optim, config[\"optimizer\"])(net.parameters(), lr=config[\"lr\"])\n",
    "#         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  \n",
    "        \n",
    "#         traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "#         validationload = data_load(file_path_validation,batch_size =  config[\"batch_size\"],datatype = 'Validation')\n",
    "        \n",
    "#         print(f'Layers: {config[\"n_layers\"]}, Layer Multiplyer: {config[\"layer_multipler\"]}, Batch size: {config[\"batch_size\"]}, LR: {config[\"lr\"]}, Optimizer: {config[\"optimizer\"]}, dropout: {config[\"drop_rate\"]}')\n",
    "#         #file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "#         #file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "#         #print('loading Data')\n",
    "#     #net=NestedUNet(4,4, layer_multipler= config[\"layer_multipler\"])   #load_model(args, class_num=4, mode='train')\n",
    "#     #optimizer = SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=1e-8)\n",
    "        \n",
    "    \n",
    "        \n",
    "#         #traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "#         #validationload = data_load(file_path_validation,batch_size = config[\"batch_size\"],datatype = 'Validation')\n",
    "    \n",
    "#         grad_sc = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         dice =1\n",
    "#         nodice =0\n",
    "#         for epoch in range(epochs):\n",
    "#         # Train Model\n",
    "#                 print(f'Epoch: {epoch}')\n",
    "#                 train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
    "#                 print('\\n\\n<Validation>')\n",
    "#                 [validloss, acc] = validation(validationload,net,epoch,device)\n",
    "#                 trial.report(validloss,epoch)\n",
    "                \n",
    "#                 if trial.should_prune():\n",
    "#                     raise optuna.exceptions.TrialPruned()\n",
    "                    \n",
    "#                 if dice > validloss:\n",
    "                    \n",
    "#                     dice = validloss\n",
    "#                     nodice=0\n",
    "#                     best_wei = net.state_dict()\n",
    "                    \n",
    "#                 elif dice < validloss:\n",
    "#                     nodice+=1\n",
    "#                     if nodice >3:\n",
    "#                         early_stop=True\n",
    "#                         torch.save(best_wei, 'nestedUnet'+ str(trial.number)+'_earlystop.pth')\n",
    "#                         return validloss\n",
    "        \n",
    "#         model_save = 'model_save_trial' + str(trial.number) + '.pth'\n",
    "#         torch.save(net.state_dict(), model_save)\n",
    "#         torch.cuda.empty_cache()\n",
    "#         return validloss   \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# # In[5]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# #if __name__ == \"__main__\":\n",
    "# file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "# file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# epochs = 15\n",
    "# studyOptuma = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),pruner=optuna.pruners.MedianPruner() )\n",
    "# studyOptuma.optimize(optumaParams, n_trials=40, gc_after_trial=True)\n",
    "# joblib.dump(studyOptuma, \"studyUnetPlusPlusNew.pkl\")\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(studyOptuma, \"studyUnetPlusPlusNew.pkl\")\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = joblib.load(\"studyUnetPlusPlus.pkl\")\n",
    "# print(\"Best trial until now:\", study.best_trial.number)\n",
    "# print(\" Params: \")\n",
    "# for key, value in study.best_trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def trainmodel(epochs):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    \n",
    "        net = NestedUNet(num_classes= 4, input_channels=4,layer_multipler= 32, n_layers=4,\n",
    "                   drop_rate= 0.1)\n",
    "        #print(f'Layer_Muti: {config[\"layer_multipler\"]}')\n",
    "        net = net.to(device)    \n",
    "        optimizer =optim.Adam(net.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max =50 )  \n",
    "        \n",
    "        traindataload = data_load(file_path_train, batch_size =16,datatype='Train')\n",
    "        validationload = data_load(file_path_validation,batch_size =16,datatype = 'Validation')\n",
    "        \n",
    "        #print(f'Layers: {config[\"n_layers\"]}, Layer Multiplyer: {config[\"layer_multipler\"]}, Batch size: {config[\"batch_size\"]}, LR: {config[\"lr\"]}, Optimizer: {config[\"optimizer\"]}, dropout: {config[\"drop_rate\"]}')\n",
    "        #file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "        #file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "        #print('loading Data')\n",
    "    #net=NestedUNet(4,4, layer_multipler= config[\"layer_multipler\"])   #load_model(args, class_num=4, mode='train')\n",
    "    #optimizer = SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=1e-8)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "        #validationload = data_load(file_path_validation,batch_size = config[\"batch_size\"],datatype = 'Validation')\n",
    "    \n",
    "        grad_sc = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        dice =1\n",
    "        nodice =0\n",
    "        for epoch in range(epochs):\n",
    "        # Train Model\n",
    "                print(f'Epoch: {epoch}')\n",
    "                train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
    "                print('\\n\\n<Validation>')\n",
    "                [validloss, acc] = validation(validationload,net,epoch,device)\n",
    "                #trial.report(validloss,epoch)\n",
    "                \n",
    "                #if trial.should_prune():\n",
    "                #    raise optuna.exceptions.TrialPruned()\n",
    "                    \n",
    "                if dice > validloss:\n",
    "                    \n",
    "                    dice = validloss\n",
    "                    nodice=0\n",
    "                    best_wei = net.state_dict()\n",
    "                    \n",
    "                elif dice < validloss:\n",
    "                    nodice+=1\n",
    "                    if nodice >3:\n",
    "                        early_stop=True\n",
    "                        torch.save(best_wei, 'nestedUnet'+ str(trial.number)+'_earlystop.pth')\n",
    "                        return validloss\n",
    "        \n",
    "                model_save = 'BestModelUnetPP_lr0001' + '.pth'\n",
    "                torch.save(net.state_dict(), model_save)\n",
    "                torch.cuda.empty_cache()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=================================================>]  Step: 1s282ms | Tot: 2h9m | Loss: 0.23666, Dice-Coef: 0.7633 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.0%, Avg loss: 0.394746, Dice: 0.605254 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 356ms | Tot: 1m37s | Loss: 0.59162, Dice-Coef: 0.4083 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.2%, Avg loss: 0.591619, Dice: 0.408381 \n",
      "\n",
      "Epoch: 1\n",
      " [=================================================>]  Step: 1s286ms | Tot: 2h8m | Loss: 0.18134, Dice-Coef: 0.8186 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.4%, Avg loss: 0.273711, Dice: 0.726289 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 360ms | Tot: 1m37s | Loss: 0.57774, Dice-Coef: 0.4222 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.5%, Avg loss: 0.577739, Dice: 0.422261 \n",
      "\n",
      "Epoch: 2\n",
      " [=================================================>]  Step: 1s258ms | Tot: 2h8m | Loss: 0.19922, Dice-Coef: 0.8007 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.5%, Avg loss: 0.241397, Dice: 0.758603 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 348ms | Tot: 1m33s | Loss: 0.56323, Dice-Coef: 0.4367 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.563233, Dice: 0.436767 \n",
      "\n",
      "Epoch: 3\n",
      " [=================================================>]  Step: 1s279ms | Tot: 2h8m | Loss: 0.25454, Dice-Coef: 0.7454 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.5%, Avg loss: 0.223034, Dice: 0.776966 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 341ms | Tot: 1m34s | Loss: 0.51975, Dice-Coef: 0.4802 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.519747, Dice: 0.480253 \n",
      "\n",
      "Epoch: 4\n",
      " [=================================================>]  Step: 1s265ms | Tot: 2h8m | Loss: 0.20680, Dice-Coef: 0.7932 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.213841, Dice: 0.786159 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 359ms | Tot: 1m35s | Loss: 0.48052, Dice-Coef: 0.5194 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.480522, Dice: 0.519478 \n",
      "\n",
      "Epoch: 5\n",
      " [=================================================>]  Step: 1s263ms | Tot: 2h8m | Loss: 0.06513, Dice-Coef: 0.9348 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.206611, Dice: 0.793389 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 343ms | Tot: 1m35s | Loss: 0.49023, Dice-Coef: 0.5097 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.490232, Dice: 0.509768 \n",
      "\n",
      "Epoch: 6\n",
      " [=================================================>]  Step: 1s254ms | Tot: 2h8m | Loss: 0.07486, Dice-Coef: 0.9251 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.197133, Dice: 0.802867 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 357ms | Tot: 1m35s | Loss: 0.41179, Dice-Coef: 0.5882 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.411791, Dice: 0.588209 \n",
      "\n",
      "Epoch: 7\n",
      " [=================================================>]  Step: 1s291ms | Tot: 2h8m | Loss: 0.21247, Dice-Coef: 0.7875 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.194524, Dice: 0.805476 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 360ms | Tot: 1m35s | Loss: 0.45419, Dice-Coef: 0.5458 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.454189, Dice: 0.545811 \n",
      "\n",
      "Epoch: 8\n",
      " [=================================================>]  Step: 1s273ms | Tot: 2h8m | Loss: 0.13423, Dice-Coef: 0.8657 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.188717, Dice: 0.811283 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 368ms | Tot: 1m35s | Loss: 0.36494, Dice-Coef: 0.6350 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.7%, Avg loss: 0.364942, Dice: 0.635058 \n",
      "\n",
      "Epoch: 9\n",
      " [=================================================>]  Step: 1s284ms | Tot: 2h8m | Loss: 0.24273, Dice-Coef: 0.7572 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.187624, Dice: 0.812376 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 343ms | Tot: 1m35s | Loss: 0.35958, Dice-Coef: 0.6404 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.7%, Avg loss: 0.359578, Dice: 0.640422 \n",
      "\n",
      "Epoch: 10\n",
      " [=================================================>]  Step: 1s279ms | Tot: 2h8m | Loss: 0.13746, Dice-Coef: 0.8625 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.182100, Dice: 0.817900 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 361ms | Tot: 1m34s | Loss: 0.38602, Dice-Coef: 0.6139 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.386017, Dice: 0.613983 \n",
      "\n",
      "Epoch: 11\n",
      " [=================================================>]  Step: 1s268ms | Tot: 2h8m | Loss: 0.15931, Dice-Coef: 0.8406 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.181626, Dice: 0.818374 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 369ms | Tot: 1m35s | Loss: 0.36524, Dice-Coef: 0.6347 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.7%, Avg loss: 0.365243, Dice: 0.634757 \n",
      "\n",
      "Epoch: 12\n",
      " [=================================================>]  Step: 1s282ms | Tot: 2h8m | Loss: 0.14460, Dice-Coef: 0.8554 6064/6064  4  \n",
      "Training epoch error: \n",
      " Acc: 99.6%, Avg loss: 0.177456, Dice: 0.822544 \n",
      "\n",
      "\n",
      "\n",
      "<Validation>\n",
      " [=================================================>]  Step: 342ms | Tot: 1m35s | Loss: 0.45509, Dice-Coef: 0.5449 271/271 1  \n",
      "Validation error: \n",
      " Acc: 99.6%, Avg loss: 0.455086, Dice: 0.544914 \n",
      "\n",
      "Epoch: 13\n",
      " [===========================>......................]  Step: 1s302ms | Tot: 1h11m | Loss: 0.25143, Dice-Coef: 0.7485 3364/6064 4  \r"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/train/\"\n",
    "    \n",
    "    \n",
    "file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/validation/\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "epochs = 40\n",
    "trainmodel(epochs)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
