{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "\n",
    "from dataprep import *\n",
    "\n",
    "import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(args):\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    cudnn.benchmark = True\n",
    "    get_logger()\n",
    "    \n",
    "    traindataload = data_load(args, datatype='Train')\n",
    "    validationload = data_load(args, datatype = 'Validation')\n",
    "    net, optimizer, best_score, start_epoch =\\\n",
    "        load_model(args, class_num=config.class_num, mode='train')\n",
    "    \n",
    "    for epoch in range(start_epoch, start_epoch+args.epochs):\n",
    "\n",
    "        # Train Model\n",
    "        print('\\n\\n\\nEpoch: {}\\n<Train>'.format(epoch))\n",
    "        net.train(True)\n",
    "        loss = 0\n",
    "        lr = args.lr * (0.5 ** (epoch // 4))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        torch.set_grad_enabled(True)\n",
    "        for idx, (inputs, targets, paths) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            if type(outputs) == tuple:\n",
    "                outputs = outputs[0]\n",
    "            batch_loss = dice_coef(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += float(batch_loss)\n",
    "            progress_bar(idx, len(trainloader), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %((loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "        log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\\\n",
    "                         %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "        logging.info(log_msg)\n",
    "\n",
    "        # Validate Model\n",
    "        print('\\n\\n<Validation>')\n",
    "        net.eval()\n",
    "        for module in net.module.modules():\n",
    "            if isinstance(module, torch.nn.modules.Dropout2d):\n",
    "                module.train(True)\n",
    "            elif isinstance(module, torch.nn.modules.Dropout):\n",
    "                module.train(True)\n",
    "            else:\n",
    "                pass\n",
    "        loss = 0\n",
    "        torch.set_grad_enabled(False)\n",
    "        for idx, (inputs, targets, paths) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            if type(outputs) == tuple:\n",
    "                outputs = outputs[0]\n",
    "            #outputs = post_process(args, inputs, outputs, save=False)\n",
    "            batch_loss = dice_coef(outputs, targets, backprop=False)\n",
    "            loss += float(batch_loss)\n",
    "            progress_bar(idx, len(validloader), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %((loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "        log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                        %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "        logging.info(log_msg)\n",
    "\n",
    "        # Save Model\n",
    "        loss /= (idx+1)\n",
    "        score = 1 - loss\n",
    "        if score > best_score:\n",
    "            checkpoint = Checkpoint(net, optimizer, epoch, score)\n",
    "            checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))\n",
    "            best_score = score\n",
    "            print(\"Saving...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=__doc__)\n",
    "    parser.add_argument(\"--resume\", type=bool, default=False,\n",
    "                        help=\"Model Trianing resume.\")\n",
    "    parser.add_argument(\"--model\", type=str, default='Unet',\n",
    "                        help=\"Model Name (unet, pspnet_squeeze, pspnet_res50,\\\n",
    "                        pspnet_res34, pspnet_res50, deeplab)\")\n",
    "    parser.add_argument(\"--in_channel\", type=int, default=1,\n",
    "                        help=\"A number of images to use for input\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=80,\n",
    "                        help=\"The batch size to load the data\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=30,\n",
    "                        help=\"The training epochs to run.\")\n",
    "    parser.add_argument(\"--drop_rate\", type=float, default=0.1,\n",
    "                        help=\"Drop-out Rate\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001,\n",
    "                        help=\"Learning rate to use in training\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"complete\",\n",
    "                        help=\"Label data type.\")\n",
    "    parser.add_argument(\"--file_path\", type=str, default=\"/home/jay/Downloads/Brats/train/\",\n",
    "                        help=\"The directory containing the training image dataset.\")\n",
    "    parser.add_argument(\"--label_root\", type=str, default=\"../../data/train/label\",\n",
    "                        help=\"The directory containing the training label datgaset\")\n",
    "    parser.add_argument(\"--output_root\", type=str, default=\"/home/jay/Downloads/Brats/prediction\",\n",
    "                        help=\"The directory containing the result predictions\")\n",
    "    parser.add_argument(\"--ckpt_root\", type=str, default=\"/home/jay/Downloads/Brats/checkpoint\",\n",
    "                        help=\"The directory containing the checkpoint files\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    trainmodel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdevice\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3810jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
