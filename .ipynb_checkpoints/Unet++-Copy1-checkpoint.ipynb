{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "from torch import Tensor\n",
    "from dataprepaug import *\n",
    "#from utils import *\n",
    "#from models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class NestedUNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(traindataload,net,optimizer, grad_sc,epoch,device):\n",
    "        \n",
    "        loss = 0\n",
    "        epoch_loss = 0\n",
    "        for idx, (inputs, targets) in enumerate(traindataload):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                #inputs = np.array(validationload)\n",
    "                print(inputs.shape)\n",
    "                print(targets.shape)\n",
    "                outputs = net(inputs)\n",
    "                batch_loss = dice_loss(outputs.softmax(1),targets, multiclass=True)\n",
    "                optimizer.zero_grad()\n",
    "                grad_sc.scale(batch_loss).backward()\n",
    "                grad_sc.step(optimizer)\n",
    "                grad_sc.update()\n",
    "                loss = batch_loss.item()\n",
    "                progress_bar(idx, len(traindataload), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %(loss, 1-loss))#(loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "                #print(f\"loss: {loss:>7f}, [{idx:>5d}/{len(traindataload):>5d}]\")\n",
    "                log_msg = '\\n'.join(['Epoch: %d, Loss: %.5f,  Dice-Coef:  %.5f' %(epoch,loss, 1-loss)])\n",
    "                logging.info(log_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(validationload,net,epoch,device):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        size=0\n",
    "        nbatch = len(validationload)\n",
    "        with torch.no_grad():\n",
    "                for idx, (inputs, targets) in enumerate(validationload):\n",
    "                        inputs, targets = inputs.to(device), targets.to(device)\n",
    "                        outputs = net(inputs)\n",
    "                        loss += dice_loss(outputs.softmax(1),targets, multiclass=True).item()\n",
    "                        acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                        size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "            \n",
    "                        \n",
    "                        progress_bar(idx, len(validationload), 'Loss: %.5f, Dice-Coef: %.5f' %(loss/(idx+1), 1-(loss/(idx+1))))\n",
    "                        log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                %(epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "                        logging.info(log_msg)\n",
    "        \n",
    "        loss /= nbatch\n",
    "        acc /= size\n",
    "        print(f\"Validation error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {loss:>8f} \\n\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    if input.dim() == 2 and reduce_batch_first:\n",
    "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')\n",
    "\n",
    "    if input.dim() == 2 or reduce_batch_first:\n",
    "        inter = torch.dot(input.reshape(-1), target.reshape(-1))\n",
    "        sets_sum = torch.sum(input) + torch.sum(target)\n",
    "        if sets_sum.item() == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    else:\n",
    "        # compute and average metric for each batch element\n",
    "        dice = 0\n",
    "        for i in range(input.shape[0]):\n",
    "            dice += dice_coeff(input[i, ...], target[i, ...])\n",
    "        return dice / input.shape[0]\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    assert input.size() == target.size()\n",
    "    dice = 0\n",
    "    for channel in range(input.shape[1]):\n",
    "        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
    "\n",
    "    return dice / input.shape[1]\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    assert input.size() == target.size()\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#_, term_width = os.popen('stty size', 'r').read().split()\n",
    "term_width = 60#int(term_width)\n",
    "\n",
    "TOTAL_BAR_LENGTH = 50.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    ''' Source Code from 'kuangliu/pytorch-cifar'\n",
    "        (https://github.com/kuangliu/pytorch-cifar/blob/master/utils.py)\n",
    "    '''\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "def format_time(seconds):\n",
    "    ''' Source Code from 'kuangliu/pytorch-cifar'\n",
    "        (https://github.com/kuangliu/pytorch-cifar/blob/master/utils.py)\n",
    "    '''\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_logger(level=\"DEBUG\", file_level=\"DEBUG\"):\n",
    "    logger = logging.getLogger(None)\n",
    "    logger.setLevel(level)\n",
    "    fomatter = logging.Formatter(\n",
    "            '%(asctime)s  [%(levelname)s]  %(message)s  (%(filename)s:  %(lineno)s)')\n",
    "    fileHandler = logging.handlers.TimedRotatingFileHandler(\n",
    "            'result.log', when='d', encoding='utf-8')\n",
    "    fileHandler.setLevel(file_level)\n",
    "    fileHandler.setFormatter(fomatter)\n",
    "    logger.addHandler(fileHandler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# def data_load(file_path, datatype,batch_size):\n",
    "    \n",
    "#     if datatype=='Train':\n",
    "#         shuffle=True\n",
    "#         data = TrainData(file_path)\n",
    "        \n",
    "        \n",
    "#     elif datatype=='Validation':\n",
    "#         data = ValidData(file_path)\n",
    "#         shuffle= False\n",
    "    \n",
    "#     elif datatype=='Test':\n",
    "#         data = TestData(file_path)\n",
    "#         shuffle= False\n",
    "#     else:\n",
    "#         raise ValueError('Choose the data type: Train, Validation, Test')\n",
    "        \n",
    "        \n",
    "#     dataload =  torch.utils.data.DataLoader(data, batch_size=batch_size, \n",
    "#                                             shuffle=shuffle, drop_last=True,pin_memory=True) \n",
    "\n",
    "    \n",
    "#     return dataload\n",
    "\n",
    "\n",
    "\n",
    "# class TrainData(torch.utils.data.Dataset):\n",
    "     \n",
    "#     def __init__(self, file_path='/home/jay/Documents/courses/Aicourse/Brats/', data_cache_size=3, transform=None):\n",
    "#         recursive=False \n",
    "#         load_data=False\n",
    "#         super().__init__()\n",
    "#         self.data_info = []\n",
    "#         self.data_cache = {}\n",
    "#         self.data_cache_size = data_cache_size\n",
    "#         self.transform = transform #Compose([\n",
    "#                     #RandomVerticalFlip(),\n",
    "#                     #RandomHorizontalFlip(),\n",
    "#                     #RandomAffine(degrees=(-20,20),translate=(0.1,0.1),\n",
    "#                     #             scale=(0.9,1.1), shear=(-0.2,0.2))])\n",
    "        \n",
    "#         # Search for all h5 files\n",
    "#         p = Path(file_path)\n",
    "#         assert(p.is_dir())\n",
    "#         if recursive:\n",
    "#             files = sorted(p.glob('**/*.h5'))\n",
    "#         else:\n",
    "#             files = sorted(p.glob('*.h5'))\n",
    "#         if len(files) < 1:\n",
    "#             raise RuntimeError('No hdf5 datasets found')\n",
    "\n",
    "#         for h5dataset_fp in files:\n",
    "#             self._add_data_infos(str(h5dataset_fp.resolve()), load_data)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         # get data\n",
    "#         x = self.get_data(\"image\", index)\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "#         else:\n",
    "#             x = torch.from_numpy(x)\n",
    "\n",
    "#         # get label\n",
    "#         y = self.get_data(\"mask\", index)\n",
    "#         y = torch.from_numpy(y)\n",
    "#         return (x, y)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.get_data_infos('image'))\n",
    "    \n",
    "#     def _add_data_infos(self, file_path, load_data):\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "#             # Walk through all groups, extracting datasets\n",
    "        \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # if data is not loaded its cache index is -1\n",
    "#                     idx = -1\n",
    "#                     if load_data:\n",
    "#                         # add data to the data cache\n",
    "                        \n",
    "#                         if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                         else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                    \n",
    "#                     # type is derived from the name of the dataset; we expect the dataset\n",
    "#                     # name to have a name such as 'data' or 'label' to identify its type\n",
    "#                     # we also store the shape of the data in case we need it\n",
    "#                     self.data_info.append({'file_path': file_path, 'type': dname, 'shape': np.shape(ds[()]), 'cache_idx': idx})\n",
    "\n",
    "#     def _load_data(self, file_path):\n",
    "#         \"\"\"Load data to the cache given the file\n",
    "#         path and update the cache index in the\n",
    "#         data_info structure.\n",
    "#         \"\"\"\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "            \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # add data to the data cache and retrieve\n",
    "#                     # the cache index\n",
    "#                     if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                     else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                            \n",
    "#                     # find the beginning index of the hdf5 file we are looking for\n",
    "#                     file_idx = next(i for i,v in enumerate(self.data_info) if v['file_path'] == file_path)\n",
    "\n",
    "#                     # the data info should have the same index since we loaded it in the same way\n",
    "#                     self.data_info[file_idx + idx]['cache_idx'] = idx\n",
    "\n",
    "#         # remove an element from data cache if size was exceeded\n",
    "#         if len(self.data_cache) > self.data_cache_size:\n",
    "#             # remove one item from the cache at random\n",
    "#             removal_keys = list(self.data_cache)\n",
    "#             removal_keys.remove(file_path)\n",
    "#             self.data_cache.pop(removal_keys[0])\n",
    "#             # remove invalid cache_idx\n",
    "            \n",
    "#             self.data_info = [{'file_path': di['file_path'], 'type': di['type'], 'shape': di['shape'], 'cache_idx': -1} if di['file_path'] == removal_keys[0] else di for di in self.data_info]\n",
    "\n",
    "#     def _add_to_cache(self, data, file_path):\n",
    "#         \"\"\"Adds data to the cache and returns its index. There is one cache\n",
    "#         list for every file_path, containing all datasets in that file.\n",
    "#         \"\"\"\n",
    "#         if file_path not in self.data_cache:\n",
    "#             self.data_cache[file_path] = [data]\n",
    "#         else:\n",
    "#             self.data_cache[file_path].append(data)\n",
    "#         #print(file_path)\n",
    "#         return len(self.data_cache[file_path]) - 1\n",
    "\n",
    "#     def get_data_infos(self, type):\n",
    "#         \"\"\"Get data infos belonging to a certain type of data.\n",
    "#         \"\"\"\n",
    "#         data_info_type = [di for di in self.data_info if di['type'] == type]\n",
    "#         return data_info_type\n",
    "\n",
    "#     def get_data(self, type, i):\n",
    "#         \"\"\"Call this function anytime you want to access a chunk of data from the\n",
    "#             dataset. This will make sure that the data is loaded in case it is\n",
    "#             not part of the data cache.\n",
    "#         \"\"\"\n",
    "#         fp = self.get_data_infos(type)[i]['file_path']\n",
    "#         if fp not in self.data_cache:\n",
    "#             self._load_data(fp)\n",
    "        \n",
    "#         # get new cache_idx assigned by _load_data_info\n",
    "#         cache_idx = self.get_data_infos(type)[i]['cache_idx']\n",
    "#         return self.data_cache[fp][cache_idx]\n",
    "\n",
    "\n",
    "# # In[5]:\n",
    "\n",
    "\n",
    "# class ValidData(torch.utils.data.Dataset):\n",
    "    \n",
    "#     def __init__(self, file_path, data_cache_size=3, transform=None):\n",
    "#         recursive=False \n",
    "#         load_data=False\n",
    "#         super().__init__()\n",
    "#         self.data_info = []\n",
    "#         self.data_cache = {}\n",
    "#         self.data_cache_size = data_cache_size\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Search for all h5 files\n",
    "#         p = Path(file_path)\n",
    "#         assert(p.is_dir())\n",
    "#         if recursive:\n",
    "#             files = sorted(p.glob('**/*.h5'))\n",
    "#         else:\n",
    "#             files = sorted(p.glob('*.h5'))\n",
    "#         if len(files) < 1:\n",
    "#             raise RuntimeError('No hdf5 datasets found')\n",
    "\n",
    "#         for h5dataset_fp in files:\n",
    "#             self._add_data_infos(str(h5dataset_fp.resolve()), load_data)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         # get data\n",
    "#         x = self.get_data(\"image\", index)\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "#         else:\n",
    "#             x = torch.from_numpy(x)\n",
    "\n",
    "#         # get label\n",
    "#         y = self.get_data(\"mask\", index)\n",
    "#         y = torch.from_numpy(y)\n",
    "#         return (x, y)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.get_data_infos('image'))\n",
    "    \n",
    "#     def _add_data_infos(self, file_path, load_data):\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "#             # Walk through all groups, extracting datasets\n",
    "        \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # if data is not loaded its cache index is -1\n",
    "#                     idx = -1\n",
    "#                     if load_data:\n",
    "#                         # add data to the data cache\n",
    "                        \n",
    "#                         if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                         else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                    \n",
    "#                     # type is derived from the name of the dataset; we expect the dataset\n",
    "#                     # name to have a name such as 'data' or 'label' to identify its type\n",
    "#                     # we also store the shape of the data in case we need it\n",
    "#                     self.data_info.append({'file_path': file_path, 'type': dname, 'shape': np.shape(ds[()]), 'cache_idx': idx})\n",
    "\n",
    "#     def _load_data(self, file_path):\n",
    "#         \"\"\"Load data to the cache given the file\n",
    "#         path and update the cache index in the\n",
    "#         data_info structure.\n",
    "#         \"\"\"\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "            \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # add data to the data cache and retrieve\n",
    "#                     # the cache index\n",
    "#                     if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                     else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                            \n",
    "#                     # find the beginning index of the hdf5 file we are looking for\n",
    "#                     file_idx = next(i for i,v in enumerate(self.data_info) if v['file_path'] == file_path)\n",
    "\n",
    "#                     # the data info should have the same index since we loaded it in the same way\n",
    "#                     self.data_info[file_idx + idx]['cache_idx'] = idx\n",
    "\n",
    "#         # remove an element from data cache if size was exceeded\n",
    "#         if len(self.data_cache) > self.data_cache_size:\n",
    "#             # remove one item from the cache at random\n",
    "#             removal_keys = list(self.data_cache)\n",
    "#             removal_keys.remove(file_path)\n",
    "#             self.data_cache.pop(removal_keys[0])\n",
    "#             # remove invalid cache_idx\n",
    "            \n",
    "#             self.data_info = [{'file_path': di['file_path'], 'type': di['type'], 'shape': di['shape'], 'cache_idx': -1} if di['file_path'] == removal_keys[0] else di for di in self.data_info]\n",
    "\n",
    "#     def _add_to_cache(self, data, file_path):\n",
    "#         \"\"\"Adds data to the cache and returns its index. There is one cache\n",
    "#         list for every file_path, containing all datasets in that file.\n",
    "#         \"\"\"\n",
    "#         if file_path not in self.data_cache:\n",
    "#             self.data_cache[file_path] = [data]\n",
    "#         else:\n",
    "#             self.data_cache[file_path].append(data)\n",
    "#         #print(file_path)\n",
    "#         return len(self.data_cache[file_path]) - 1\n",
    "\n",
    "#     def get_data_infos(self, type):\n",
    "#         \"\"\"Get data infos belonging to a certain type of data.\n",
    "#         \"\"\"\n",
    "#         data_info_type = [di for di in self.data_info if di['type'] == type]\n",
    "#         return data_info_type\n",
    "\n",
    "#     def get_data(self, type, i):\n",
    "#         \"\"\"Call this function anytime you want to access a chunk of data from the\n",
    "#             dataset. This will make sure that the data is loaded in case it is\n",
    "#             not part of the data cache.\n",
    "#         \"\"\"\n",
    "#         fp = self.get_data_infos(type)[i]['file_path']\n",
    "#         if fp not in self.data_cache:\n",
    "#             self._load_data(fp)\n",
    "        \n",
    "#         # get new cache_idx assigned by _load_data_info\n",
    "#         cache_idx = self.get_data_infos(type)[i]['cache_idx']\n",
    "#         return self.data_cache[fp][cache_idx]\n",
    "\n",
    "\n",
    "# # In[6]:\n",
    "\n",
    "\n",
    "# class TestData(torch.utils.data.Dataset):\n",
    "#     def __init__(self, file_path, data_cache_size=3, transform=None):\n",
    "#         recursive=False \n",
    "#         load_data=False\n",
    "#         super().__init__()\n",
    "#         self.data_info = []\n",
    "#         self.data_cache = {}\n",
    "#         self.data_cache_size = data_cache_size\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Search for all h5 files\n",
    "#         p = Path(file_path)\n",
    "#         assert(p.is_dir())\n",
    "#         if recursive:\n",
    "#             files = sorted(p.glob('**/*.h5'))\n",
    "#         else:\n",
    "#             files = sorted(p.glob('*.h5'))\n",
    "#         if len(files) < 1:\n",
    "#             raise RuntimeError('No hdf5 datasets found')\n",
    "\n",
    "#         for h5dataset_fp in files:\n",
    "#             self._add_data_infos(str(h5dataset_fp.resolve()), load_data)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         # get data\n",
    "#         x = self.get_data(\"image\", index)\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "#         else:\n",
    "#             x = torch.from_numpy(x)\n",
    "\n",
    "#         # get label\n",
    "#         y = self.get_data(\"mask\", index)\n",
    "#         y = torch.from_numpy(y)\n",
    "#         return (x, y)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.get_data_infos('image'))\n",
    "    \n",
    "#     def _add_data_infos(self, file_path, load_data):\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "#             # Walk through all groups, extracting datasets\n",
    "        \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # if data is not loaded its cache index is -1\n",
    "#                     idx = -1\n",
    "#                     if load_data:\n",
    "#                         # add data to the data cache\n",
    "                        \n",
    "#                         if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                         else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                    \n",
    "#                     # type is derived from the name of the dataset; we expect the dataset\n",
    "#                     # name to have a name such as 'data' or 'label' to identify its type\n",
    "#                     # we also store the shape of the data in case we need it\n",
    "#                     self.data_info.append({'file_path': file_path, 'type': dname, 'shape': np.shape(ds[()]), 'cache_idx': idx})\n",
    "\n",
    "#     def _load_data(self, file_path):\n",
    "#         \"\"\"Load data to the cache given the file\n",
    "#         path and update the cache index in the\n",
    "#         data_info structure.\n",
    "#         \"\"\"\n",
    "#         with h5py.File(file_path) as h5_file:\n",
    "            \n",
    "#                 for dname, ds in h5_file.items():\n",
    "#                     # add data to the data cache and retrieve\n",
    "#                     # the cache index\n",
    "#                     if dname == 'mask':\n",
    "#                             maskinit = ds[()]\n",
    "#                             mask = np.dstack((np.sum(maskinit,axis=2)==0,maskinit))\n",
    "#                             #mask = np.zeros(np.shape(ds[()]))\n",
    "#                             mask[:,:,1] = mask[:,:,1]\n",
    "#                             mask[:,:,2] = mask[:,:,2]\n",
    "#                             mask[:,:,3] = mask[:,:,3]\n",
    "#                             #maskflat = mask[:,:,0]+mask[:,:,1]+mask[:,:,2]\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             maskflat = np.float32(mask.T)\n",
    "#                             #maskflat= np.expand_dims(np.array(maskflat), 0)\n",
    "#                             idex = self._add_to_cache(maskflat, file_path)\n",
    "                            \n",
    "#                     else:\n",
    "#                             image = ds[()]#np.zeros(np.shape(ds[()]))\n",
    "#                             image[image<0] = np.nan\n",
    "#                             #image = (image - np.nanmean(image,axis=(0,1)))/np.nanstd(image,axis=(0,1))\n",
    "                            \n",
    "#                             image[:,:,0] = (image[:,:,0]- np.nanmean(image[:,:,0]))/np.nanstd(image[:,:,0])#cv2.normalize(ds[()][:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[:,:,1] = image[:,:,1] = (image[:,:,1]- np.nanmean(image[:,:,1]))/np.nanstd(image[:,:,1])\n",
    "#                             image[:,:,2] = image[:,:,2] = (image[:,:,2]- np.nanmean(image[:,:,2]))/np.nanstd(image[:,:,2])\n",
    "#                             image[:,:,3] = image[:,:,3] = (image[:,:,3]- np.nanmean(image[:,:,3]))/np.nanstd(image[:,:,3])\n",
    "#                             #image[:,:,1] = (ds[()][:,:,1]- np.nanmean(ds[()][:,:,1]))/np.nanstd(ds[()][:,:,1])#cv2.normalize(ds[()][:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,2] = (ds[()][:,:,2]- np.nanmean(ds[()][:,:,2]))/np.nanstd(ds[()][:,:,2])#cv2.normalize(ds[()][:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             #image[:,:,3] = (ds[()][:,:,3]- np.nanmean(ds[()][:,:,3]))/np.nanstd(ds[()][:,:,3])#cv2.normalize(ds[()][:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)\n",
    "#                             image[np.isnan(image)] = 0\n",
    "#                             image = np.float32(image.T)\n",
    "#                             idx = self._add_to_cache(image, file_path)\n",
    "                            \n",
    "#                     # find the beginning index of the hdf5 file we are looking for\n",
    "#                     file_idx = next(i for i,v in enumerate(self.data_info) if v['file_path'] == file_path)\n",
    "\n",
    "#                     # the data info should have the same index since we loaded it in the same way\n",
    "#                     self.data_info[file_idx + idx]['cache_idx'] = idx\n",
    "\n",
    "#         # remove an element from data cache if size was exceeded\n",
    "#         if len(self.data_cache) > self.data_cache_size:\n",
    "#             # remove one item from the cache at random\n",
    "#             removal_keys = list(self.data_cache)\n",
    "#             removal_keys.remove(file_path)\n",
    "#             self.data_cache.pop(removal_keys[0])\n",
    "#             # remove invalid cache_idx\n",
    "            \n",
    "#             self.data_info = [{'file_path': di['file_path'], 'type': di['type'], 'shape': di['shape'], 'cache_idx': -1} if di['file_path'] == removal_keys[0] else di for di in self.data_info]\n",
    "\n",
    "#     def _add_to_cache(self, data, file_path):\n",
    "#         \"\"\"Adds data to the cache and returns its index. There is one cache\n",
    "#         list for every file_path, containing all datasets in that file.\n",
    "#         \"\"\"\n",
    "#         if file_path not in self.data_cache:\n",
    "#             self.data_cache[file_path] = [data]\n",
    "#         else:\n",
    "#             self.data_cache[file_path].append(data)\n",
    "#         #print(file_path)\n",
    "#         return len(self.data_cache[file_path]) - 1\n",
    "\n",
    "#     def get_data_infos(self, type):\n",
    "#         \"\"\"Get data infos belonging to a certain type of data.\n",
    "#         \"\"\"\n",
    "#         data_info_type = [di for di in self.data_info if di['type'] == type]\n",
    "#         return data_info_type\n",
    "\n",
    "#     def get_data(self, type, i):\n",
    "#         \"\"\"Call this function anytime you want to access a chunk of data from the\n",
    "#             dataset. This will make sure that the data is loaded in case it is\n",
    "#             not part of the data cache.\n",
    "#         \"\"\"\n",
    "#         fp = self.get_data_infos(type)[i]['file_path']\n",
    "#         if fp not in self.data_cache:\n",
    "#             self._load_data(fp)\n",
    "        \n",
    "#         # get new cache_idx assigned by _load_data_info\n",
    "#         cache_idx = self.get_data_infos(type)[i]['cache_idx']\n",
    "#         return self.data_cache[fp][cache_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tv.utils import _log_api_usage_once\n",
    "# from torchvision.transforms import functional as F\n",
    "# from torchvision.transforms.functional import InterpolationMode, _interpolation_modes_from_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import pdb\n",
    "import os\n",
    "import numbers\n",
    "import numpy as np\n",
    "import math\n",
    "import PIL\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import collections\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "\n",
    "def data_load(file_path, datatype,batch_size):\n",
    "    \n",
    "    if datatype=='Train':\n",
    "        shuffle=True\n",
    "        data = TrainData(file_path)\n",
    "        \n",
    "        \n",
    "    elif datatype=='Validation':\n",
    "        data = ValidData(file_path)\n",
    "        shuffle= False\n",
    "    \n",
    "    elif datatype=='Test':\n",
    "        data = TestData(file_path)\n",
    "        shuffle= False\n",
    "    else:\n",
    "        raise ValueError('Choose the data type: Train, Validation, Test')\n",
    "        \n",
    "        \n",
    "    dataload =  torch.utils.data.DataLoader(data, batch_size=batch_size, \n",
    "                                            shuffle=shuffle, drop_last=True,pin_memory=True) \n",
    "\n",
    "    \n",
    "    return dataload\n",
    "    \n",
    "class TrainData(torch.utils.data.Dataset):\n",
    "     \n",
    "    def __init__(self, file_path='/home/jay/Documents/courses/Aicourse/Brats/', data_cache_size=3, transform=None):\n",
    "        \n",
    "        files = sorted(glob.glob(file_path+'*.h5'))\n",
    "        self.files = files\n",
    "        self.transform = Compose([\n",
    "                    RandomVerticalFlip(),\n",
    "                    RandomHorizontalFlip(),\n",
    "                    RandomAffine(degrees=(-20,20),translate=(0.1,0.1),\n",
    "                                 scale=(0.9,1.1), shear=(-0.2,0.2))]) \n",
    "        \n",
    "        self.totensor = transforms.ToTensor()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):    \n",
    "     \t        \n",
    "        return len(self.files)\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "                idx = np.random.randint(len(self.files))\n",
    "                img_path = self.files[idx]\n",
    "                \n",
    "                data = h5py.File(img_path, 'r')\n",
    "                img = data['image']\n",
    "                img = img[()]\n",
    "                mask = data['mask']\n",
    "                mask = mask[()]\n",
    "                mask = np.dstack((np.sum(mask,axis=2)==0,mask))*255\n",
    "                \n",
    "                img[img<0] = np.nan\n",
    "                \n",
    "                img[:,:,0] = cv2.normalize(img[:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,0]/np.max(img[:,:,0]))*255 #(img[:,:,0]- np.nanmean(img[:,:,0]))/np.nanstd(img[:,:,0])\n",
    "                \n",
    "                img[:,:,1] = cv2.normalize(img[:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,1]/np.max(img[:,:,1]))*255#(img[:,:,1]- np.nanmean(img[:,:,1]))/np.nanstd(img[:,:,1])\n",
    "        \n",
    "                img[:,:,2] = cv2.normalize(img[:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,2]/np.max(img[:,:,2]))*255#(img[:,:,2]- np.nanmean(img[:,:,2]))/np.nanstd(img[:,:,2])\n",
    "            \n",
    "                img[:,:,3] = cv2.normalize(img[:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,3]/np.max(img[:,:,3]))*255#(img[:,:,3]- np.nanmean(img[:,:,3]))/np.nanstd(img[:,:,3])\n",
    "                img[np.isnan(img)] = 0\n",
    "                \n",
    "                #print(np.shape(img))\n",
    "                \n",
    "                #print(np.unique(img))\n",
    "                img = transforms.ToPILImage()(np.uint8(img))\n",
    "                mask = transforms.ToPILImage()(np.uint8(mask))\n",
    "                \n",
    "                #print(np.shape(mask))\n",
    "                #                 img = img.permute(2,0,1)\n",
    "#                 mask = mask.permute(2,0,1)\n",
    "                \n",
    "#                 img= img.numpy()\n",
    "#                 mask= mask.numpy()\n",
    "#                 img =  Image.fromarray(img)\n",
    "#                 mask = Image.fromarray(mask)\n",
    "                img, label = self.transform(img, mask)\n",
    "                label= np.array(label)\n",
    "                label = label.astype(np.float32)\n",
    "                \n",
    "                labelb = label[:,:,1:4]\n",
    "                labelbs = np.dstack((np.sum(labelb,axis=2)==0,labelb))\n",
    "                \n",
    "                labelbs = np.array(labelbs).astype(np.float32)\n",
    "                labelbs = torch.from_numpy(labelbs)\n",
    "                labelbs = labelbs.permute(2,0,1).float()\n",
    "                #label = label.permute(3,1,2).float()\n",
    "                #print(img_path)\n",
    "                return self.totensor(img), labelbs          \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "class ValidData(torch.utils.data.Dataset):\n",
    "     \n",
    "    def __init__(self, file_path='/home/jay/Documents/courses/Aicourse/Brats/', data_cache_size=3, transform=None):\n",
    "        \n",
    "        files = sorted(glob.glob(file_path+'*.h5'))\n",
    "        self.files = files\n",
    "        \n",
    "        \n",
    "        self.totensor = transforms.ToTensor()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):    \n",
    "     \t        \n",
    "        return len(self.files)\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "                \n",
    "                img_path = self.files[idx]\n",
    "                \n",
    "                data = h5py.File(img_path, 'r')\n",
    "                img = data['image']\n",
    "                img = img[()]\n",
    "                mask = data['mask']\n",
    "                mask = mask[()]\n",
    "                mask = np.dstack((np.sum(mask,axis=2)==0,mask))*255\n",
    "                \n",
    "                img[img<0] = np.nan\n",
    "                \n",
    "                img[:,:,0] = cv2.normalize(img[:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,0]/np.max(img[:,:,0]))*255 #(img[:,:,0]- np.nanmean(img[:,:,0]))/np.nanstd(img[:,:,0])\n",
    "                \n",
    "                img[:,:,1] = cv2.normalize(img[:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,1]/np.max(img[:,:,1]))*255#(img[:,:,1]- np.nanmean(img[:,:,1]))/np.nanstd(img[:,:,1])\n",
    "        \n",
    "                img[:,:,2] = cv2.normalize(img[:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,2]/np.max(img[:,:,2]))*255#(img[:,:,2]- np.nanmean(img[:,:,2]))/np.nanstd(img[:,:,2])\n",
    "            \n",
    "                img[:,:,3] = cv2.normalize(img[:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,3]/np.max(img[:,:,3]))*255#(img[:,:,3]- np.nanmean(img[:,:,3]))/np.nanstd(img[:,:,3])\n",
    "                img[np.isnan(img)] = 0\n",
    "                \n",
    "                #print(np.shape(img))\n",
    "                \n",
    "                #print(np.unique(img))\n",
    "                img = transforms.ToPILImage()(np.uint8(img))\n",
    "                mask = transforms.ToPILImage()(np.uint8(mask))\n",
    "                \n",
    "                #print(np.shape(mask))\n",
    "                #                 img = img.permute(2,0,1)\n",
    "#                 mask = mask.permute(2,0,1)\n",
    "                \n",
    "#                 img= img.numpy()\n",
    "#                 mask= mask.numpy()\n",
    "#                 img =  Image.fromarray(img)\n",
    "#                 mask = Image.fromarray(mask)\n",
    "                img, label = self.transform(img, mask)\n",
    "                label= np.array(label)\n",
    "                label = label.astype(np.float32)\n",
    "                label = torch.from_numpy(label)\n",
    "                \n",
    "                #label = label.permute(3,1,2).float()\n",
    "                #print(img_path)\n",
    "                return self.totensor(img), label               \n",
    "\n",
    "\n",
    "class TestData(torch.utils.data.Dataset):\n",
    "     \n",
    "    def __init__(self, file_path='/home/jay/Documents/courses/Aicourse/Brats/', data_cache_size=3, transform=None):\n",
    "        \n",
    "        files = sorted(glob.glob(file_path+'*.h5'))\n",
    "        self.files = files\n",
    "        \n",
    "        \n",
    "        self.totensor = transforms.ToTensor()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):    \n",
    "     \t        \n",
    "        return len(self.files)\n",
    "     \n",
    "    def __getitem__(self, idx):\n",
    "                \n",
    "                img_path = self.files[idx]\n",
    "                \n",
    "                data = h5py.File(img_path, 'r')\n",
    "                img = data['image']\n",
    "                img = img[()]\n",
    "                mask = data['mask']\n",
    "                mask = mask[()]\n",
    "                mask = np.dstack((np.sum(mask,axis=2)==0,mask))*255\n",
    "                \n",
    "                img[img<0] = np.nan\n",
    "                \n",
    "                img[:,:,0] = cv2.normalize(img[:,:,0],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,0]/np.max(img[:,:,0]))*255 #(img[:,:,0]- np.nanmean(img[:,:,0]))/np.nanstd(img[:,:,0])\n",
    "                \n",
    "                img[:,:,1] = cv2.normalize(img[:,:,1],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,1]/np.max(img[:,:,1]))*255#(img[:,:,1]- np.nanmean(img[:,:,1]))/np.nanstd(img[:,:,1])\n",
    "        \n",
    "                img[:,:,2] = cv2.normalize(img[:,:,2],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,2]/np.max(img[:,:,2]))*255#(img[:,:,2]- np.nanmean(img[:,:,2]))/np.nanstd(img[:,:,2])\n",
    "            \n",
    "                img[:,:,3] = cv2.normalize(img[:,:,3],None, norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_32F)*255#(img[:,:,3]/np.max(img[:,:,3]))*255#(img[:,:,3]- np.nanmean(img[:,:,3]))/np.nanstd(img[:,:,3])\n",
    "                img[np.isnan(img)] = 0\n",
    "                \n",
    "                #print(np.shape(img))\n",
    "                \n",
    "                #print(np.unique(img))\n",
    "                img = transforms.ToPILImage()(np.uint8(img))\n",
    "                mask = transforms.ToPILImage()(np.uint8(mask))\n",
    "                \n",
    "                #print(np.shape(mask))\n",
    "                #                 img = img.permute(2,0,1)\n",
    "#                 mask = mask.permute(2,0,1)\n",
    "                \n",
    "#                 img= img.numpy()\n",
    "#                 mask= mask.numpy()\n",
    "#                 img =  Image.fromarray(img)\n",
    "#                 mask = Image.fromarray(mask)\n",
    "                img, label = self.transform(img, mask)\n",
    "                label= np.array(label)\n",
    "                label = label.astype(np.float32)\n",
    "                label = torch.from_numpy(label)\n",
    "                \n",
    "                #label = label.permute(3,1,2).float()\n",
    "                #print(img_path)\n",
    "                return self.totensor(img), label            \n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "#############################################################\n",
    "#                                                           #\n",
    "#       Data Transforms Functions                           # \n",
    "#                                                           #\n",
    "#############################################################\n",
    "\n",
    "'''\n",
    "    From torchvision Transforms.py (+ Slightly changed)\n",
    "    (https://github.com/pytorch/vision/blob/master/torchvision/transforms/transforms.py)\n",
    "'''\n",
    "class Compose(object):\n",
    "    \"\"\"Composes several transforms together.\n",
    "    Args:\n",
    "        transforms (list of ``Transform`` objects): list of transforms to compose.\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.CenterCrop(10),\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>> ])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        for t in self.transforms:\n",
    "            img,label = t(img, label)\n",
    "        return img, label\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '('\n",
    "        for t in self.transforms:\n",
    "            format_string += '\\n'\n",
    "            format_string += '    {0}'.format(t)\n",
    "        format_string += '\\n)'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "    Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, pic, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "        Returns:\n",
    "            Tensor: Converted image.\n",
    "        \"\"\"\n",
    "        return to_tensor(pic), to_tensor(label)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "class RandomVerticalFlip(object):\n",
    "    \"\"\"Vertically flip the given PIL Image randomly with a given probability.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return vflip(img), vflip(label)\n",
    "        return img, label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Horizontally flip the given PIL Image randomly with a given probability.\n",
    "    Args:\n",
    "        p (float): probability of the image being flipped. Default value is 0.5\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be flipped.\n",
    "        Returns:\n",
    "            PIL Image: Randomly flipped image.\n",
    "        \"\"\"\n",
    "        if random.random() < self.p:\n",
    "            return hflip(img), hflip(label)\n",
    "        return img, label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(p={})'.format(self.p)\n",
    "\n",
    "\n",
    "class RandomRotation(object):\n",
    "    \"\"\"Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter. See `filters`_ for more information.\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    .. _filters: https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees=360, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        #angle = random.uniform(degrees[0], degrees[1])\n",
    "        angle_list = [0,90,180,270]\n",
    "        angle = random.choice(angle_list)\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "\n",
    "        #angle = self.get_params(self.degrees)\n",
    "        angle = np.random.randint(self.degrees[0], self.degrees[1])\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center),\\\n",
    "                rotate(label, angle, self.resample, self.expand, self.center)\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + '(degrees={0}'.format(self.degrees)\n",
    "        format_string += ', resample={0}'.format(self.resample)\n",
    "        format_string += ', expand={0}'.format(self.expand)\n",
    "        if self.center is not None:\n",
    "            format_string += ', center={0}'.format(self.center)\n",
    "        format_string += ')'\n",
    "        return format_string\n",
    "\n",
    "\n",
    "class RandomAffine(object):\n",
    "    \"\"\"Random affine transformation of the image keeping center invariant\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees). Set to 0 to deactivate rotations.\n",
    "        translate (tuple, optional): tuple of maximum absolute fraction for horizontal\n",
    "            and vertical translations. For example translate=(a, b), then horizontal shift\n",
    "            is randomly sampled in the range -img_width * a < dx < img_width * a and vertical shift is\n",
    "            randomly sampled in the range -img_height * b < dy < img_height * b. Will not translate by default.\n",
    "        scale (tuple, optional): scaling factor interval, e.g (a, b), then scale is\n",
    "            randomly sampled from the range a <= scale <= b. Will keep original scale by default.\n",
    "        shear (sequence or float or int, optional): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees). Will not apply shear by default\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter. See `filters`_ for more information.\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        fillcolor (int): Optional fill color for the area outside the transform in the output image. (Pillow>=5.0.0)\n",
    "    .. _filters: https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            assert isinstance(degrees, (tuple, list)) and len(degrees) == 2, \\\n",
    "                \"degrees should be a list or tuple and it must be of length 2.\"\n",
    "            self.degrees = degrees\n",
    "\n",
    "        if translate is not None:\n",
    "            assert isinstance(translate, (tuple, list)) and len(translate) == 2, \\\n",
    "                \"translate should be a list or tuple and it must be of length 2.\"\n",
    "            for t in translate:\n",
    "                if not (0.0 <= t <= 1.0):\n",
    "                    raise ValueError(\"translation values should be between 0 and 1\")\n",
    "        self.translate = translate\n",
    "\n",
    "        if scale is not None:\n",
    "            assert isinstance(scale, (tuple, list)) and len(scale) == 2, \\\n",
    "                \"scale should be a list or tuple and it must be of length 2.\"\n",
    "            for s in scale:\n",
    "                if s <= 0:\n",
    "                    raise ValueError(\"scale values should be positive\")\n",
    "        self.scale = scale\n",
    "\n",
    "        if shear is not None:\n",
    "            if isinstance(shear, numbers.Number):\n",
    "                if shear < 0:\n",
    "                    raise ValueError(\"If shear is a single number, it must be positive.\")\n",
    "                self.shear = (-shear, shear)\n",
    "            else:\n",
    "                assert isinstance(shear, (tuple, list)) and len(shear) == 2, \\\n",
    "                    \"shear should be a list or tuple and it must be of length 2.\"\n",
    "                self.shear = shear\n",
    "        else:\n",
    "            self.shear = shear\n",
    "\n",
    "        self.resample = resample\n",
    "        self.fillcolor = fillcolor\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees, translate, scale_ranges, shears, img_size):\n",
    "        \"\"\"Get parameters for affine transformation\n",
    "        Returns:\n",
    "            sequence: params to be passed to the affine transformation\n",
    "        \"\"\"\n",
    "        angle = random.uniform(degrees[0], degrees[1])\n",
    "        if translate is not None:\n",
    "            max_dx = translate[0] * img_size[0]\n",
    "            max_dy = translate[1] * img_size[1]\n",
    "            translations = (np.round(random.uniform(-max_dx, max_dx)),\n",
    "                            np.round(random.uniform(-max_dy, max_dy)))\n",
    "        else:\n",
    "            translations = (0, 0)\n",
    "\n",
    "        if scale_ranges is not None:\n",
    "            scale = random.uniform(scale_ranges[0], scale_ranges[1])\n",
    "        else:\n",
    "            scale = 1.0\n",
    "\n",
    "        if shears is not None:\n",
    "            shear = random.uniform(shears[0], shears[1])\n",
    "        else:\n",
    "            shear = 0.0\n",
    "\n",
    "        return angle, translations, scale, shear\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be transformed.\n",
    "        Returns:\n",
    "            PIL Image: Affine transformed image.\n",
    "        \"\"\"\n",
    "        ret = self.get_params(self.degrees, self.translate, self.scale, self.shear, img.size)\n",
    "        return affine(img, label, *ret, resample=self.resample, fillcolor=self.fillcolor)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = '{name}(degrees={degrees}'\n",
    "        if self.translate is not None:\n",
    "            s += ', translate={translate}'\n",
    "        if self.scale is not None:\n",
    "            s += ', scale={scale}'\n",
    "        if self.shear is not None:\n",
    "            s += ', shear={shear}'\n",
    "        if self.resample > 0:\n",
    "            s += ', resample={resample}'\n",
    "        if self.fillcolor != 0:\n",
    "            s += ', fillcolor={fillcolor}'\n",
    "        s += ')'\n",
    "        d = dict(self.__dict__)\n",
    "        d['resample'] = _pil_interpolation_to_str[d['resample']]\n",
    "        return s.format(name=self.__class__.__name__, **d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    From torchvision functional.py (+ Slightly changed)\n",
    "    (https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py)\n",
    "'''\n",
    "def _is_pil_image(img):\n",
    "    if accimage is not None:\n",
    "        return isinstance(img, (Image.Image, accimage.Image))\n",
    "    else:\n",
    "        return isinstance(img, Image.Image)\n",
    "\n",
    "def to_tensor(pic):\n",
    "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "    See ``ToTensor`` for more details.\n",
    "    Args:\n",
    "        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
    "    Returns:\n",
    "        Tensor: Converted image.\n",
    "    \"\"\"\n",
    "    if not(_is_pil_image(pic) or _is_numpy_image(pic)):\n",
    "        raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\n",
    "\n",
    "    if isinstance(pic, np.ndarray):\n",
    "        # handle numpy array\n",
    "        img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
    "        # backward compatibility\n",
    "        if isinstance(img, torch.ByteTensor):\n",
    "            return img.float().div(255)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    if accimage is not None and isinstance(pic, accimage.Image):\n",
    "        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n",
    "        pic.copyto(nppic)\n",
    "        return torch.from_numpy(nppic)\n",
    "\n",
    "    # handle PIL Image\n",
    "    if pic.mode == 'I':\n",
    "        img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
    "    elif pic.mode == 'I;16':\n",
    "        img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
    "    elif pic.mode == 'F':\n",
    "        img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
    "    elif pic.mode == '1':\n",
    "        img = 255 * torch.from_numpy(np.array(pic, np.uint8, copy=False))\n",
    "    else:\n",
    "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
    "    # PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "    if pic.mode == 'YCbCr':\n",
    "        nchannel = 3\n",
    "    elif pic.mode == 'I;16':\n",
    "        nchannel = 1\n",
    "    else:\n",
    "        nchannel = len(pic.mode)\n",
    "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
    "    # put it from HWC to CHW format\n",
    "    # yikes, this transpose takes 80% of the loading time/CPU\n",
    "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "    if isinstance(img, torch.ByteTensor):\n",
    "        return img.float().div(255)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def vflip(img):\n",
    "    \"\"\"Vertically flip the given PIL Image.\n",
    "    Args:\n",
    "        img (PIL Image): Image to be flipped.\n",
    "    Returns:\n",
    "        PIL Image:  Vertically flipped image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "def hflip(img):\n",
    "    \"\"\"Horizontally flip the given PIL Image.\n",
    "    Args:\n",
    "        img (PIL Image): Image to be flipped.\n",
    "    Returns:\n",
    "        PIL Image:  Horizontall flipped image.\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "    \"\"\"Rotate the image by angle.\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be rotated.\n",
    "        angle (float or int): In degrees degrees counter clockwise order.\n",
    "        resample (``PIL.Image.NEAREST`` or ``PIL.Image.BILINEAR`` or ``PIL.Image.BICUBIC``, optional):\n",
    "            An optional resampling filter. See `filters`_ for more information.\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to ``PIL.Image.NEAREST``.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    .. _filters: https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n",
    "    \"\"\"\n",
    "\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "\n",
    "def _get_inverse_affine_matrix(center, angle, translate, scale, shear):\n",
    "    # Helper method to compute inverse matrix for affine transformation\n",
    "\n",
    "    # As it is explained in PIL.Image.rotate\n",
    "    # We need compute INVERSE of affine transformation matrix: M = T * C * RSS * C^-1\n",
    "    # where T is translation matrix: [1, 0, tx | 0, 1, ty | 0, 0, 1]\n",
    "    #       C is translation matrix to keep center: [1, 0, cx | 0, 1, cy | 0, 0, 1]\n",
    "    #       RSS is rotation with scale and shear matrix\n",
    "    #       RSS(a, scale, shear) = [ cos(a)*scale    -sin(a + shear)*scale     0]\n",
    "    #                              [ sin(a)*scale    cos(a + shear)*scale     0]\n",
    "    #                              [     0                  0          1]\n",
    "    # Thus, the inverse is M^-1 = C * RSS^-1 * C^-1 * T^-1\n",
    "\n",
    "    angle = math.radians(angle)\n",
    "    shear = math.radians(shear)\n",
    "    scale = 1.0 / scale\n",
    "\n",
    "    # Inverted rotation matrix with scale and shear\n",
    "    d = math.cos(angle + shear) * math.cos(angle) + math.sin(angle + shear) * math.sin(angle)\n",
    "    matrix = [\n",
    "        math.cos(angle + shear), math.sin(angle + shear), 0,\n",
    "        -math.sin(angle), math.cos(angle), 0\n",
    "    ]\n",
    "    matrix = [scale / d * m for m in matrix]\n",
    "\n",
    "    # Apply inverse of translation and of center translation: RSS^-1 * C^-1 * T^-1\n",
    "    matrix[2] += matrix[0] * (-center[0] - translate[0]) + matrix[1] * (-center[1] - translate[1])\n",
    "    matrix[5] += matrix[3] * (-center[0] - translate[0]) + matrix[4] * (-center[1] - translate[1])\n",
    "\n",
    "    # Apply center translation: C * RSS^-1 * C^-1 * T^-1\n",
    "    matrix[2] += center[0]\n",
    "    matrix[5] += center[1]\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def affine(img, label, angle, translate, scale, shear, resample=0, fillcolor=None):\n",
    "    \"\"\"Apply affine transformation on the image keeping image center invariant\n",
    "    Args:\n",
    "        img (PIL Image): PIL Image to be rotated.\n",
    "        angle (float or int): rotation angle in degrees between -180 and 180, clockwise direction.\n",
    "        translate (list or tuple of integers): horizontal and vertical translations(post-rotation translation)\n",
    "        scale (float): overall scale\n",
    "        shear (float): shear angle value in degrees between -180 to 180, clockwise direction.\n",
    "        resample (``PIL.Image.NEAREST`` or ``PIL.Image.BILINEAR`` or ``PIL.Image.BICUBIC``, optional):\n",
    "            An optional resampling filter.\n",
    "            See `filters`_ for more information.\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to ``PIL.Image.NEAREST``.\n",
    "        fillcolor (int): Optional fill color for the area outside the transform in the output image. (Pillow>=5.0.0)\n",
    "    \"\"\"\n",
    "    if not _is_pil_image(img):\n",
    "        raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\n",
    "\n",
    "    assert isinstance(translate, (tuple, list)) and len(translate) == 2, \\\n",
    "        \"Argument translate should be a list or tuple of length 2\"\n",
    "\n",
    "    assert scale > 0.0, \"Argument scale should be positive\"\n",
    "\n",
    "    output_size = img.size\n",
    "    center = (img.size[0] * 0.5 + 0.5, img.size[1] * 0.5 + 0.5)\n",
    "    matrix = _get_inverse_affine_matrix(center, angle, translate, scale, shear)\n",
    "    kwargs = {}\n",
    "    return img.transform(output_size, Image.AFFINE, matrix, resample, **kwargs),\\\n",
    "            label.transform(output_size, Image.AFFINE, matrix, resample, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\tsource code From.\n",
    "\thttps://gist.github.com/oeway/2e3b989e0343f0884388ed7ed82eb3b0\n",
    "\"\"\"\n",
    "\n",
    "class ElasticTransform(object):\n",
    "    \"\"\"Apply elastic transformation on a numpy.ndarray (H x W x C)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, sigma):\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, image, label):\n",
    "        if isinstance(self.alpha, collections.Sequence):\n",
    "            alpha = random_num_generator(self.alpha)\n",
    "        else:\n",
    "            alpha = self.alpha\n",
    "        if isinstance(self.sigma, collections.Sequence):\n",
    "            sigma = random_num_generator(self.sigma)\n",
    "        else:\n",
    "            sigma = self.sigma\n",
    "        return elastic_transform(image, label, alpha=alpha, sigma=sigma)\n",
    "\n",
    "\n",
    "def elastic_transform(image, label, alpha=1000, sigma=30, spline_order=1, mode='nearest', random_state=np.random):\n",
    "    \"\"\"Elastic deformation of image as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    #assert image.ndim == 3\n",
    "    image = np.array(image)\n",
    "    label = np.array(label)\n",
    "    shape = image.shape[:2]\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
    "                         sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = [np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))]\n",
    "\n",
    "    result1 = map_coordinates(image, indices, order=spline_order, mode=mode).reshape(shape)\n",
    "    result2 = map_coordinates(label, indices, order=spline_order, mode=mode).reshape(shape)\n",
    "    return Image.fromarray(result1), Image.fromarray(result2)\n",
    "\n",
    "\n",
    "def random_num_generator(config, random_state=np.random):\n",
    "    if config[0] == 'uniform':\n",
    "        ret = random_state.uniform(config[1], config[2], 1)[0]\n",
    "    elif config[0] == 'lognormal':\n",
    "        ret = random_state.lognormal(config[1], config[2], 1)[0]\n",
    "    else:\n",
    "        print(config)\n",
    "        raise Exception('unsupported format')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = NestedUNet(4,4)\n",
    "net=net.to(device)\n",
    "grad_sc = torch.cuda.amp.GradScaler(enabled=True)\n",
    "start_epoch=0\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size=2\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "\n",
    "print(device)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "traindataload = data_load('/home/jay/Documents/courses/Aicourse/Brats/train/', datatype='Train',batch_size=batch_size)\n",
    "validationload = data_load('/home/jay/Documents/courses/Aicourse/Brats/validation/', datatype = 'Validation', batch_size=batch_size)\n",
    "\n",
    "\n",
    "#print(np.shape(traindataload))\n",
    "if device == 'cuda:0':\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "traindataload = data_load('/home/jay/Documents/courses/Aicourse/Brats/train/', datatype='Train',batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([20, 4, 240, 240])\n",
      "Shape of y:  torch.Size([20, 4, 240, 240]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for X, y in traindataload:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "torch.Size([20, 4, 240, 240])\n",
      "torch.Size([20, 4, 240, 240])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 142.00 MiB (GPU 0; 5.81 GiB total capacity; 3.45 GiB already allocated; 60.06 MiB free; 3.74 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mepochs):\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraindataload\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<Validation>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m         validloss \u001b[38;5;241m=\u001b[39m validation(validationload,net,epoch,device)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(traindataload, net, optimizer, grad_sc, epoch, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m dice_loss(outputs\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m1\u001b[39m),targets, multiclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mNestedUNet.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     66\u001b[0m x2_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_0(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x1_0))\n\u001b[1;32m     67\u001b[0m x1_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_1(torch\u001b[38;5;241m.\u001b[39mcat([x1_0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x2_0)], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 68\u001b[0m x0_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv0_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx0_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m x3_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3_0(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x2_0))\n\u001b[1;32m     71\u001b[0m x2_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_1(torch\u001b[38;5;241m.\u001b[39mcat([x2_0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x3_0)], \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mVGGBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 15\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    393\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    394\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 142.00 MiB (GPU 0; 5.81 GiB total capacity; 3.45 GiB already allocated; 60.06 MiB free; 3.74 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+epochs):\n",
    "        # Train Model\n",
    "        print(f'Epoch: {epoch}')\n",
    "        train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
    "        print('\\n\\n<Validation>')\n",
    "        validloss = validation(validationload,net,epoch,device)\n",
    "        \n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for X, y in traindataload:\n",
    "    image = X.to(device)\n",
    "    #image = image.permute(0,3,1,2).float()\n",
    "    #sample = net(image)\n",
    "    \n",
    "    #sample = sample.argmax(1)\n",
    "    \n",
    "    batchidx = 5\n",
    "    plt.subplots(1,4,figsize = (20,20))\n",
    "    for i in range(4):\n",
    "        img_np = image[batchidx,i,:,:].cpu().detach().numpy()\n",
    "        print(np.max(img_np))\n",
    "        plt.subplot(1,4,1+i)\n",
    "        plt.imshow(img_np)\n",
    "    plt.colormaps()    \n",
    "    plt.show()\n",
    "        \n",
    "    plt.subplots(1,4,figsize = (20,20))\n",
    "    for i in range(4):\n",
    "        print(y.shape)\n",
    "        img_np = y[batchidx,i,:,:].detach().numpy()\n",
    "        print(np.max(img_np))\n",
    "        plt.subplot(1,4,1+i)\n",
    "        plt.imshow(img_np)\n",
    "    plt.colormaps()\n",
    "    plt.show()\n",
    "    #torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for X, y in traindataload:\n",
    "    image = X.to(device)\n",
    "    #image = image.permute(0,3,1,2).float()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    batchidx = 19\n",
    "    plt.subplots(1,4,figsize = (20,20))\n",
    "    for i in range(4):\n",
    "        img_np = image[batchidx,i,:,:].cpu().detach().numpy()\n",
    "        img_np = img_np==i\n",
    "        plt.subplot(1,4,1+i)\n",
    "        plt.imshow(img_np)\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
