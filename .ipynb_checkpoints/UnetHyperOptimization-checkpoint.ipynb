{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "import joblib\n",
    "from torch.optim import Adam, SGD\n",
    "from dataprepaug import *\n",
    "from utils import *\n",
    "from models import *\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "#from models.unet_model import UNet\n",
    "#from models.UnetPlusPlus import NestedUNet\n",
    "\n",
    "#from .pspnet import *\n",
    "#from .deeplab import *\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from models.unet import *\n",
    "import glob\n",
    "import os\n",
    "import numbers\n",
    "import math\n",
    "import PIL\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import collections\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from optuna import Trial\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-22 11:29:57,813]\u001b[0m A new study created in memory with name: no-name-7e28bce6-e528-4ae2-8740-18f7b32a3264\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 4, Layer Multiplyer: 45, Batch size: 4, LR: 2.2601402302869636e-05, Optimizer: SGD, dropout: 0.019941000375380675\n",
      "Epoch: 0\n",
      " [>.................................................]  Step: 3s4ms | Tot: 0ms | Loss: 0.89464, Dice-Coef: 0.1053 1/3100 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [>.................................................]  Step: 290ms | Tot: 10s766ms | Loss: 0.88963, Dice-Coef: 0.1103 38/3100 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-dfedd226cb0e>\", line 157, in <module>\n",
      "    studyOptuma.optimize(optumaParams, n_trials=50, gc_after_trial=True)\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/optuna/study/study.py\", line 400, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    trial = _run_trial(study, func, catch)\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-2-dfedd226cb0e>\", line 106, in optumaParams\n",
      "    train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
      "  File \"<ipython-input-2-dfedd226cb0e>\", line 16, in train\n",
      "    grad_sc.step(optimizer)\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 338, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 284, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"/home/jay/.local/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 284, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 721, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 381, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 358, in normpath\n",
      "    if comp in (empty, dot):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(traindataload,net,optimizer, grad_sc,epoch,device):\n",
    "        \n",
    "        loss = 0\n",
    "        epoch_loss = 0\n",
    "        size=0\n",
    "        acc=0\n",
    "        nbatch = len(traindataload)\n",
    "        for idx, (inputs, targets) in enumerate(traindataload):\n",
    "                torch.cuda.empty_cache()\n",
    "                inputs, targets = inputs.to(device).to(memory_format=torch.contiguous_format), targets.to(device).to(memory_format=torch.contiguous_format)\n",
    "                outputs = net(inputs)\n",
    "                size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "                batch_loss = dice_loss(outputs.softmax(1),targets, multiclass=True)\n",
    "                optimizer.zero_grad()\n",
    "                grad_sc.scale(batch_loss).backward()\n",
    "                grad_sc.step(optimizer)\n",
    "                grad_sc.update()\n",
    "                loss = batch_loss.item()\n",
    "                epoch_loss += loss\n",
    "                acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                progress_bar(idx, len(traindataload), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %(loss, 1-loss))#(loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "                log_msg = '\\n'.join(['Training (%d/%d): Epoch: %d, Loss: %.5f,  Dice-Coef:  %.5f' %(idx,nbatch, epoch,loss, 1-loss)])\n",
    "                logging.info(log_msg)\n",
    "        epoch_loss /= nbatch\n",
    "        acc /= size\n",
    "        \n",
    "        print(f\"Training epoch error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {epoch_loss:>8f}, Dice: {(1-epoch_loss):>8f} \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def validation(validationload,net,epoch,device):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        size=0\n",
    "        nbatch = len(validationload)\n",
    "        with torch.no_grad():\n",
    "                for idx, (inputs, targets) in enumerate(validationload):\n",
    "                        torch.cuda.empty_cache()\n",
    "                        inputs, targets = inputs.to(device).to(memory_format=torch.contiguous_format), targets.to(device).to(memory_format=torch.contiguous_format)\n",
    "                        outputs = net(inputs)\n",
    "                        loss += dice_loss(outputs.softmax(1),targets, multiclass=True).item()\n",
    "                        acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                        size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "            \n",
    "                        \n",
    "                        progress_bar(idx, len(validationload), 'Loss: %.5f, Dice-Coef: %.5f' %(loss/(idx+1), 1-(loss/(idx+1))))\n",
    "                        log_msg = '\\n'.join(['Validation (%d/%d): Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                %(idx, nbatch, epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "                        logging.info(log_msg)\n",
    "        \n",
    "        loss /= nbatch\n",
    "        acc /= size\n",
    "        torch.cuda.empty_cache()                \n",
    "        print(f\"Validation error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {loss:>8f}, Dice: {(1-loss):>8f} \\n\")\n",
    "        return loss, acc\n",
    "                                \n",
    "        \n",
    "        \n",
    "    \n",
    "def optumaParams(trial):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        config = {\n",
    "        \"layer_multipler\": trial.suggest_int(\"layer_multipler\", 16,49),\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-1, 1e-1),\n",
    "        \"drop_rate\": trial.suggest_loguniform(\"drop_rate\", 1e-2, 2.5e-1),\n",
    "        \"n_layers\": trial.suggest_int(\"n_layers\",3,4),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\",4,24),\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"SGD\", \"Adam\", \"RMSprop\"])\n",
    "    }\n",
    "\n",
    "        \n",
    "        net = UNet(4,4, layer_multipler= config[\"layer_multipler\"], n_layers=config[\"n_layers\"], useBN=True,\n",
    "                   drop_rate=config[\"drop_rate\"])\n",
    "        #print(f'Layer_Muti: {config[\"layer_multipler\"]}')\n",
    "        net = net.to(device)    \n",
    "        optimizer = getattr(optim, config[\"optimizer\"])(net.parameters(), lr=config[\"lr\"])\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  \n",
    "        \n",
    "        traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "        validationload = data_load(file_path_validation,batch_size =  config[\"batch_size\"],datatype = 'Validation')\n",
    "        \n",
    "        print(f'Layers: {config[\"n_layers\"]}, Layer Multiplyer: {config[\"layer_multipler\"]}, Batch size: {config[\"batch_size\"]}, LR: {config[\"lr\"]}, Optimizer: {config[\"optimizer\"]}, dropout: {config[\"drop_rate\"]}')\n",
    "        #file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "        #file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "        #print('loading Data')\n",
    "    #net=NestedUNet(4,4, layer_multipler= config[\"layer_multipler\"])   #load_model(args, class_num=4, mode='train')\n",
    "    #optimizer = SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=1e-8)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "        #validationload = data_load(file_path_validation,batch_size = config[\"batch_size\"],datatype = 'Validation')\n",
    "    \n",
    "        grad_sc = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        dice =1\n",
    "        nodice =0\n",
    "        for epoch in range(epochs):\n",
    "        # Train Model\n",
    "                print(f'Epoch: {epoch}')\n",
    "                train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
    "                print('\\n\\n<Validation>')\n",
    "                [validloss, acc] = validation(validationload,net,epoch,device)\n",
    "                trial.report(validloss,epoch)\n",
    "                \n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "                    \n",
    "                if dice > validloss:\n",
    "                    \n",
    "                    dice = validloss\n",
    "                    nodice=0\n",
    "                    best_wei = net.state_dict()\n",
    "                    \n",
    "                elif dice < validloss:\n",
    "                    nodice+=1\n",
    "                    if nodice >3:\n",
    "                        early_stop=True\n",
    "                        torch.save(best_wei, 'nestedUnet'+ str(trial.number)+'_earlystop.pth')\n",
    "                        return validloss\n",
    "        \n",
    "        model_save = 'model_save_trial' + str(trial.number) + '.pth'\n",
    "        torch.save(net.state_dict(), model_save)\n",
    "        torch.cuda.empty_cache()\n",
    "        return validloss   \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "epochs = 20\n",
    "studyOptuma = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),pruner=optuna.pruners.MedianPruner() )\n",
    "studyOptuma.optimize(optumaParams, n_trials=50, gc_after_trial=True)\n",
    "joblib.dump(studyOptuma, \"studyUnet.pkl\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(\"study.pkl\")\n",
    "print(\"Best trial until now:\", study.best_trial.number)\n",
    "print(\" Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
