{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.optim import Adam, SGD\n",
    "from dataprepaug import *\n",
    "from utils import *\n",
    "from models import *\n",
    "from functools import partial\n",
    "from models.unet_model import UNet\n",
    "from models.UnetPlusPlus import NestedUNet\n",
    "#from .pspnet import *\n",
    "#from .deeplab import *\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(config,checkpoint_dir=None):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(device)\n",
    "    cudnn.benchmark = True\n",
    "    get_logger()\n",
    "    \n",
    "    file_path_train = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/train/\"\n",
    "    \n",
    "    \n",
    "    file_path_validation = \"/home/jay/Documents/courses/Aicourse/Brats/HYPER/validation/\"\n",
    "    print('loading Data')\n",
    "    net=NestedUNet(4,4, layer_multipler= config[\"layer_multipler\"])   #load_model(args, class_num=4, mode='train')\n",
    "    optimizer = SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9, weight_decay=1e-8)\n",
    "        \n",
    "    net=net.to(device)\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    \n",
    "    \n",
    "    traindataload = data_load(file_path_train, batch_size = config[\"batch_size\"],datatype='Train')\n",
    "    validationload = data_load(file_path_validation,batch_size = config[\"batch_size\"],datatype = 'Validation')\n",
    "    \n",
    "    grad_sc = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    for epoch in range(10):\n",
    "        # Train Model\n",
    "        print(f'Epoch: {epoch}')\n",
    "        \n",
    "        \n",
    "        print('Training Data Load')\n",
    "        loss = 0\n",
    "        epoch_loss = 0\n",
    "        size=0\n",
    "        acc=0\n",
    "        nbatch = len(traindataload)\n",
    "        for idx, (inputs, targets) in enumerate(traindataload):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "                batch_loss = dice_loss(outputs.softmax(1),targets, multiclass=True)\n",
    "                optimizer.zero_grad()\n",
    "                grad_sc.scale(batch_loss).backward()\n",
    "                grad_sc.step(optimizer)\n",
    "                grad_sc.update()\n",
    "                loss = batch_loss.item()\n",
    "                epoch_loss += loss\n",
    "                acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                progress_bar(idx, len(traindataload), 'Loss: %.5f, Dice-Coef: %.5f'\n",
    "                         %(loss, 1-loss))#(loss/(idx+1)), (1-(loss/(idx+1)))))\n",
    "                #log_msg = '\\n'.join(['Training (%d/%d): Epoch: %d, Loss: %.5f,  Dice-Coef:  %.5f' %(idx,nbatch, epoch,loss, 1-loss)])\n",
    "                #logging.info(log_msg)\n",
    "        epoch_loss /= nbatch\n",
    "        acc /= size\n",
    "        print(f\"Training epoch error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {epoch_loss:>8f}, Dice: {(1-epoch_loss):>8f} \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    size=0\n",
    "    nbatch = len(validationload)\n",
    "    with torch.no_grad():\n",
    "            for idx, (inputs, targets) in enumerate(validationload):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = net(inputs)\n",
    "                    loss += dice_loss(outputs.softmax(1),targets, multiclass=True).item()\n",
    "                    acc += (outputs.argmax(1) == targets.argmax(1)).type(torch.float).sum().item()\n",
    "                    size += outputs.shape[0]*outputs.shape[2]*outputs.shape[3]\n",
    "            \n",
    "                        \n",
    "                        #progress_bar(idx, len(validationload), 'Loss: %.5f, Dice-Coef: %.5f' %(loss/(idx+1), 1-(loss/(idx+1))))\n",
    "                    log_msg = '\\n'.join(['Validation (%d/%d): Epoch: %d  Loss: %.5f,  Dice-Coef:  %.5f'\n",
    "                %(idx, nbatch, epoch, loss/(idx+1), 1-(loss/(idx+1)))])\n",
    "                    logging.info(log_msg)\n",
    "        \n",
    "    loss /= nbatch\n",
    "    acc /= size\n",
    "                        \n",
    "    print(f\"Validation error: \\n Acc: {(100*acc):>0.1f}%, Avg loss: {loss:>8f}, Dice: {(1-loss):>8f} \\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    ckpt_root = \"/home/jay/Documents/courses/Aicourse/Brats/checkpointUnetPlusPlusHYPER/\"\n",
    "        #train(traindataload,net,optimizer, grad_sc,epoch,device)\n",
    "        #print('\\n\\n<Validation>')\n",
    "        #[validloss, acc] = validation(validationload,net,epoch,device)\n",
    "       \n",
    "        # Save Model\n",
    "        #loss /= (idx+1)\n",
    "        #score = 1 - validloss\n",
    "        #if score > best_score:\n",
    "        #checkpoint = Checkpoint(net, optimizer, epoch, score)\n",
    "        #checkpoint.save(os.path.join(args.ckpt_root, args.model+'.tar'))\n",
    "        #best_score = score\n",
    "        #print(\"Saving...\")\n",
    "        \n",
    "    with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        torch.save(\n",
    "            (net.state_dict(), optimizer.state_dict()), path)\n",
    "        \n",
    "#        with tune.checkpoint_dir(epoch) as ckpt_root:\n",
    "                \n",
    "#                path = os.path.join(ckpt_root, \"checkpoint\")\n",
    "#                torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "    tune.report(loss=loss, accuracy=acc)\n",
    "        \n",
    "#        print(\"Saving...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_samples=1\n",
    "max_num_epochs=10\n",
    "gpus_per_trial=1\n",
    "print(device)\n",
    "cudnn.benchmark = True\n",
    "config = {\n",
    "        \"layer_multipler\": tune.choice([0.5,1,2,3,4,5]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Run tune run line\n"
     ]
    }
   ],
   "source": [
    "print('Here')\n",
    "reporter = CLIReporter(\n",
    "        parameter_columns=[\"layer_multipler\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "print('Run tune run line')\n",
    "result = tune.run(\n",
    "        trainmodel,\n",
    "        config=config,\n",
    "        resources_per_trial={\"gpu\": 1},\n",
    "        \n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Remote functions cannot be called directly. Instead of running '__main__.my_function()', try '__main__.my_function.remote()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-54caf7fe2379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m my_function(1\n\u001b[0m\u001b[1;32m      2\u001b[0m            )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/ray/remote_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         raise TypeError(\"Remote functions cannot be called directly. Instead \"\n\u001b[0m\u001b[1;32m    145\u001b[0m                         \u001b[0;34mf\"of running '{self._function_name}()', \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                         f\"try '{self._function_name}.remote()'.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: Remote functions cannot be called directly. Instead of running '__main__.my_function()', try '__main__.my_function.remote()'."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
